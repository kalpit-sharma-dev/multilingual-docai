# GPU-Optimized Dockerfile for PS-05 Challenge (A100 GPU)
# Optimized for Ubuntu 24.04, 48-core CPU, 256GB RAM, A100 GPU

# Use CUDA 12.1 devel image on Ubuntu 22.04 (A100 compatible and available)
FROM nvidia/cuda:12.1.1-devel-ubuntu22.04

# Build args to control optional large model fetches during build
ARG INCLUDE_BLIP2=1
ARG PREFETCH_PADDLEOCR=1

# Set environment variables for optimization
ENV DEBIAN_FRONTEND=noninteractive
ENV CUDA_HOME=/usr/local/cuda
ENV PATH=${CUDA_HOME}/bin:${PATH}
ENV LD_LIBRARY_PATH=${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}
ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility
ENV TRANSFORMERS_CACHE=/app/models
ENV HF_HOME=/app/models
ENV MPLCONFIGDIR=/tmp
ENV HF_HUB_OFFLINE=1
ENV TRANSFORMERS_OFFLINE=1

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3.11 \
    python3.11-dev \
    python3.11-venv \
    python3-pip \
    git \
    wget \
    curl \
    build-essential \
    cmake \
    pkg-config \
    libgl1 \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    libtesseract-dev \
    tesseract-ocr \
    tesseract-ocr-eng \
    tesseract-ocr-hin \
    tesseract-ocr-urd \
    tesseract-ocr-ara \
    tesseract-ocr-nep \
    tesseract-ocr-fas \
    poppler-utils \
    imagemagick \
    ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# Create symbolic links for Python
RUN ln -sf /usr/bin/python3.11 /usr/bin/python

# Set working directory
WORKDIR /app

# Copy requirements
COPY requirements_gpu_optimized.txt .

# Install Python dependencies with GPU optimization
# Ensure pip is installed for Python 3.11 and install deps into 3.11 site-packages
RUN python3.11 -m ensurepip --upgrade || true
RUN python3.11 -m pip install --no-cache-dir --upgrade pip setuptools wheel
RUN python3.11 -m pip install --no-cache-dir -r requirements_gpu_optimized.txt

# Optional GPU extras removed for compatibility; core GPU deps come from requirements
# (torch/cu121, torchvision, torchaudio). Install NVML bindings only via requirements file.

# Pre-fetch fastText model for language ID to avoid first-run delay
RUN curl -L -o /app/lid.176.bin https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin

# Copy application code
COPY backend/ ./backend/
COPY scripts/ ./scripts/
COPY ps05.py ./

# Create necessary directories
RUN mkdir -p datasets results logs models data/api_datasets data/api_results models/easyocr
## Include pre-fetched models in the image if present at build time
COPY models/ ./models/

# Pre-fetch HuggingFace models for offline use (can be skipped if models mounted)
# These steps rely on internet during build; set HF_HOME to /app/models to cache inside image
ENV HF_HOME=/app/models
ENV TRANSFORMERS_CACHE=/app/models
# Copy and run fetch_models to populate models into image (BLIP-2 optional via INCLUDE_BLIP2)
COPY scripts/utilities/fetch_models.py /app/scripts/utilities/fetch_models.py
RUN if [ "$INCLUDE_BLIP2" = "1" ]; then \
      HF_HUB_OFFLINE=0 TRANSFORMERS_OFFLINE=0 python3.11 /app/scripts/utilities/fetch_models.py --target /app/models \
        --layoutlm microsoft/layoutlmv3-base \
        --pix2struct google/pix2struct-textcaps-base \
        --table google/flan-t5-small \
        --bertscore roberta-large ; \
    else \
      HF_HUB_OFFLINE=0 TRANSFORMERS_OFFLINE=0 python3.11 /app/scripts/utilities/fetch_models.py --target /app/models \
        --layoutlm microsoft/layoutlmv3-base \
        --pix2struct google/pix2struct-textcaps-base \
        --table google/flan-t5-small \
        --bertscore roberta-large \
        --skip-blip2 ; \
    fi

# Ensure YOLOv8x weights exist inside the image
RUN python3.11 - <<'PY'
try:
    from ultralytics.utils.downloads import attempt_download
    attempt_download("yolov8x.pt", dir="/app/models")
    print("Downloaded yolov8x.pt to /app/models")
except Exception as e:
    print("Failed to pre-download yolov8x.pt:", e)
PY

# Materialize local checkpoints so code paths work fully offline
RUN HF_HUB_OFFLINE=0 TRANSFORMERS_OFFLINE=0 python3.11 - <<'PY'
from transformers import LayoutLMv3Processor, LayoutLMv3ForSequenceClassification
from transformers import Blip2Processor, Blip2ForConditionalGeneration
from transformers import Pix2StructProcessor, Pix2StructForConditionalGeneration
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

def save_layoutlmv3_six_class():
    try:
        base = "microsoft/layoutlmv3-base"
        proc = LayoutLMv3Processor.from_pretrained(base)
        model = LayoutLMv3ForSequenceClassification.from_pretrained(base, num_labels=6)
        proc.save_pretrained("/app/models/layoutlmv3-6class")
        model.save_pretrained("/app/models/layoutlmv3-6class")
        print("Saved LayoutLMv3 6-class head to /app/models/layoutlmv3-6class")
    except Exception as e:
        print("Skipping LayoutLMv3 materialization:", e)

def save_blip2():
    try:
        name = "Salesforce/blip2-opt-2.7b"
        proc = Blip2Processor.from_pretrained(name)
        model = Blip2ForConditionalGeneration.from_pretrained(name)
        proc.save_pretrained("/app/models/blip2-opt-2.7b")
        model.save_pretrained("/app/models/blip2-opt-2.7b")
        print("Saved BLIP-2 to /app/models/blip2-opt-2.7b")
    except Exception as e:
        print("Skipping BLIP-2 materialization:", e)

def save_pix2struct():
    try:
        name = "google/pix2struct-textcaps-base"
        proc = Pix2StructProcessor.from_pretrained(name)
        model = Pix2StructForConditionalGeneration.from_pretrained(name)
        proc.save_pretrained("/app/models/pix2struct-chart")
        model.save_pretrained("/app/models/pix2struct-chart")
        print("Saved Pix2Struct to /app/models/pix2struct-chart")
    except Exception as e:
        print("Skipping Pix2Struct materialization:", e)

def save_table_t2t():
    try:
        name = "google/flan-t5-small"
        tok = AutoTokenizer.from_pretrained(name)
        model = AutoModelForSeq2SeqLM.from_pretrained(name)
        tok.save_pretrained("/app/models/table-t2t")
        model.save_pretrained("/app/models/table-t2t")
        print("Saved table T2T to /app/models/table-t2t")
    except Exception as e:
        print("Skipping table T2T materialization:", e)

save_layoutlmv3_six_class()
save_blip2()
save_pix2struct()
save_table_t2t()
PY

# Ensure yolov8x weights are provided under ./models before build; they will be copied by the models/ COPY above

# Copy any provided local models over (overrides)
COPY models/ ./models/

ENV EASYOCR_MODEL_PATH=/app/models/easyocr
RUN HF_HUB_OFFLINE=0 TRANSFORMERS_OFFLINE=0 python3.11 - <<'PY'
import easyocr
def prepare(group):
    try:
        easyocr.Reader(group, gpu=False, model_storage_directory='/app/models/easyocr', download_enabled=True)
        print('EasyOCR cache prepared for', group)
    except Exception as e:
        print('EasyOCR prefetch skipped for', group, ':', e)
# Arabic-compatible set with English
prepare(['ar','fa','ur','en'])
# Hindi set (with English)
prepare(['hi','en'])
# Nepali set (with English)
prepare(['ne','en'])
# English baseline
prepare(['en'])
PY

# PaddleOCR: install and prefetch English models (others can be added if needed)
RUN python3.11 -m pip install --no-cache-dir paddleocr==2.7.0.3 || true
RUN python3.11 - <<'PY'
langs = {
    'en': ['en'],
    'hi': ['hi', 'devanagari'],
    'ur': ['ur', 'arabic'],
    'ar': ['ar', 'arabic'],
    'ne': ['ne', 'devanagari'],
    'fa': ['fa', 'arabic', 'persian'],
}
try:
    from paddleocr import PaddleOCR
    for lang_name, candidates in langs.items():
        prepared = False
        for code in candidates:
            try:
                PaddleOCR(use_angle_cls=True, lang=code, use_gpu=False)
                print(f'PaddleOCR cache prepared for {lang_name} via code {code}')
                prepared = True
                break
            except Exception as e:
                print(f'PaddleOCR prefetch attempt failed for {lang_name} code {code}: {e}')
        if not prepared:
            print(f'PaddleOCR cache NOT prepared for {lang_name}; EasyOCR offline cache will be used as fallback')
except Exception as e:
    print('PaddleOCR prefetch skipped entirely:', e)
PY

# Set permissions
RUN chmod +x ps05.py

# Expose port
EXPOSE 8000

# Set environment variables for optimization
ENV PYTHONPATH=/app
ENV CUDA_LAUNCH_BLOCKING=0
ENV TORCH_CUDNN_V8_API_ENABLED=1
ENV TORCH_CUDNN_V8_API_DISABLED=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_LAYOUTLM=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_YOLO=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_BLIP=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_OCR=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_FASTTEXT=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_TRANSFORMERS=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_ULTRALYTICS=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_EASYOCR=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_FASTTEXT=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_PIL=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_OPENCV=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_NUMPY=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_PANDAS=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_SCIPY=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_MATPLOTLIB=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_SEABORN=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_PLOTLY=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_SCIKIT_LEARN=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_NLTK=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_SPACY=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_ALBUMENTATIONS=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_IMGAUG=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_IMAGEHASH=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_PYMUPDF=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_PYPDF2=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_PYTHON_DOCX=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_PYTHON_PPTX=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_FASTAPI=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_UVICORN=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_PYTHON_MULTIPART=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_PYDANTIC=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_AIOHTTP=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_ASYNCIO_MQTT=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_PATHLIB2=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_WATCHDOG=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_LOGURU=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_PROMETHEUS_CLIENT=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_PYTEST=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_PYTEST_ASYNCIO=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_BLACK=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_FLAKE8=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_MYPY=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_CUPY_CUDA12X=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_NUMBA=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_ONNX=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_ONNXRUNTIME_GPU=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_TENSORRT=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_ACCELERATE=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_DEEPSPEED=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_TENSORBOARD=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_WANDB=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_TQDM=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_CLICK=0
ENV TORCH_CUDNN_V8_API_DISABLED_FOR_RICH=0

# Default model checkpoint envs inside image (can be overridden at run-time)
ENV YOLO_WEIGHTS=/app/models/yolov8x.pt
ENV LAYOUTLMV3_CHECKPOINT=/app/models/layoutlmv3-6class
ENV BLIP2_CHECKPOINT=/app/models/blip2-opt-2.7b
ENV CHART_CAPTION_CHECKPOINT=/app/models/pix2struct-chart
ENV TABLE_T2T_CHECKPOINT=/app/models/table-t2t

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Default command (serve FastAPI)
CMD ["python", "-m", "uvicorn", "backend.app.main:app", "--host", "0.0.0.0", "--port", "8000"]
